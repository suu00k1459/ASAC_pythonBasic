{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "in8j-e-lsQ8A"
   },
   "source": [
    "# VGG 논문\n",
    "https://arxiv.org/pdf/1409.1556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z4AbWY8VbiYZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANaakmhmsZ9C"
   },
   "source": [
    "* 3차원 이미지를 대상으로 CNN구조를 만들 때!!!!   \n",
    "    --> 집중의 대상은 2차원 사이즈 중심!!!  \n",
    "    ( 뒤에 있는 채널에 대한 것들은 생략!!!!!--> 니가 알아서 연결)  \n",
    "    --> 필터의 수와 연동이 되니까 코드가 알아서..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2CCH_3jcW6x"
   },
   "outputs": [],
   "source": [
    "# 1) Conv2D 레이어에 대한 세팅!!(채널은 신경 안 쓰겠다!!!)\n",
    "# - kernel_size : 필터에 대한 2차원 사이즈(어느 사이즈로 스캔할지)\n",
    "#                 3*3, 5*5, 7*7 etc 특징들을 추출..,\n",
    "#                 ==> Output인 Feature Map의 사이즈에 연동!!!\n",
    "# - filters : 몇 개의 필터를 사용할지.....\n",
    "#             <==> Feature Map을 몇 장 만들어 낼지!!!!!!!\n",
    "#                  output인 Feature Map의 Channel의 수!!!\n",
    "# - stride  : 가로 step, 세로 step\n",
    "#             얼마나 자세하게 스캐닝을 할지/말지..\n",
    "#             ==> Feature Map의 Size에 연관!!!!\n",
    "# - padding : 테두리에 대한 처리( 사이즈 보전을 할지 말지..)\n",
    "#             valid : 그냥 테두리 없이 스캐닝하자\n",
    "#             same  : 니가 내가 지정한 kernel_size에 맞춰서\n",
    "#                     입력과 동일한 Feature Map이 나오도록\n",
    "#                      테두리 처리를 해주라!!!\n",
    "# +++ ActivationFunction : 초기 버전들은 AF을 사용X\n",
    "#                          VGG 모델 전후로 AF을 사용을 함..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qYo7aVV1cXUn"
   },
   "outputs": [],
   "source": [
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    # 우리가 신경쓸 부분은 오로지 2D!!!\n",
    "    # 나머지 : channel은 코드가 알아서!!!!\n",
    "    kernel_size = (5,5),\n",
    "    filters = 4,\n",
    "    strides = (2,2),\n",
    "    padding = \"same\"\n",
    "    # ++ 최근에는 Activation Function\n",
    "    # activation=\"relu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TCCGw9ncYkI"
   },
   "outputs": [],
   "source": [
    "# Pooling Layer\n",
    "# --> Feature Map의 결과들을 대표화를 하는 과정!!!!!\n",
    "#     ( 일반적으로 사이즈들을 줄이는 것을 선호)\n",
    "# - pool_size : 처리가 되는 단위 : 대표화의 단위( 2,2)\n",
    "# - strides : 옵션도 같이 활용....\n",
    "\n",
    "pool1 = tf.keras.layers.MaxPool2D(\n",
    "    pool_size = (2,2),\n",
    "    strides = (2,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5AlRhcecemI"
   },
   "outputs": [],
   "source": [
    "# + 연결이 많아서....\n",
    "# --> 중간에 적당학게 연결을 짜르는 Dropout\n",
    "# 참고) 최종적인 FeatureMap을 분류DNN구조와 연결을 할 때...\n",
    "#       FullConnection을 주로 활용을 함..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbbAs0dkxJ08"
   },
   "source": [
    "#### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxTFwoWOciYo",
    "outputId": "45d19672-3aba-458e-d225-169388e724d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_X, train_y),(test_X, test_y) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bmkV--RDckIZ"
   },
   "outputs": [],
   "source": [
    "# 전처리 : 이미지 전처리 --> 1/255.0으로 정규화\n",
    "train_X = train_X/255.0\n",
    "test_X = test_X /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x23YG7eXcpU3"
   },
   "outputs": [],
   "source": [
    "# ===> 간단하게 하기 위해서 흑백 사진을 사용을 하였음..\n",
    "# 보통은 컬러이미지를 가지고 수행을 함!!!!\n",
    "# + 컬러 자체로 할지 // 흑백으로 채널을 줄여서 할지..결정!!!!\n",
    "# ( 컬러의 특징이 중요하지 않을 때... )\n",
    "\n",
    "# ==> 전통적인 이미지 처리 : openCV(c/c++--> 모든 언어)\n",
    "#     colab의 opencv는 일반적인 opencv와 채널의 순서가 다름..\n",
    "#     푸르딩딩으로 나옴;;;RGB--> BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tT4dTUnVc3WL"
   },
   "outputs": [],
   "source": [
    "# 1. 입력에 대한 데이터 처리!!!!!!!\n",
    "# ===> 1장에 대해서 처리!!!!!!\n",
    "#       n장에 대해서 일괄 처리는 코드가 TF가 알아서 함.....\n",
    "# ==> 1장에 대해서 잘 코드화!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZqqVsByxr_j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ze7DNrZrc5wV",
    "outputId": "25b8a08c-9203-4afe-cc05-af67a233527c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_X[0].shape)\n",
    "\n",
    "\n",
    "# 모델의 구조도에 맞춰서 데이터셋을 변형!!!!!\n",
    "# 3d ---> 4d (데이터 수, 가로, 세로, 채널)\n",
    "# 현재 데이터 셋 : 60000, 28 X 28 X 1 [3D]\n",
    "# 원하는 입력 데이터 셋 : 60000, 28, 28, 1 [4D]\n",
    "# 이런 식으로 입력 데이터셋을 변경해야 신경 쓸 일이 없음\n",
    "\n",
    "train_X = train_X.reshape(-1 ,28,28,1)\n",
    "test_X  = test_X.reshape(-1, 28,28,1)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_X[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbgxCOUXdLTv",
    "outputId": "fbf116b9-e6ea-4184-e2d1-2541a773ddf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x79ed9ac0c970>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 가장 간단한 CNN구조 모델!!!!\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    # Step1) 입력 + 이미지 특징 추출\n",
    "    # 입력 : 1장 데이터를 기준 --> 28,28,1// (60000,28,28,1)\n",
    "    tf.keras.layers.Conv2D( input_shape=(28,28,1),\n",
    "                            kernel_size=(3,3),\n",
    "                            filters = 16\n",
    "                            ),\n",
    "\n",
    "    # 2번 conv 레이어\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3),\n",
    "                           filters=32\n",
    "                           ),\n",
    "\n",
    "    # 3번 conv 레이터\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3),\n",
    "                           filters=64),\n",
    "\n",
    "\n",
    "\n",
    "    # ==== (이미지가 가진 특징을 잘 뽑아냈다고 가정) ==== #\n",
    "\n",
    "\n",
    "    # Step2) 분류를 위한 DNN구조!!!!!\n",
    "    # 차원을 변경\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # ++ 일반적 분류를 위한 레이어 추가\n",
    "    #    노드 수, AF, 몇 개 레이어를 쌓을지 HP\n",
    "    tf.keras.layers.Dense( units = 128, activation=\"relu\"),\n",
    "\n",
    "    # Step3) 출력용\n",
    "    tf.keras.layers.Dense( units = 10, activation=\"softmax\")\n",
    "])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1GGoMYTdMWD",
    "outputId": "7b6aa0e5-b35a-4ba6-c033-b94d67ce80e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3965056   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3989642 (15.22 MB)\n",
      "Trainable params: 3989642 (15.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTEW6En6dTFy"
   },
   "outputs": [],
   "source": [
    "# 기본적인 cnn구조로 설계한 네트워크의 학습!\n",
    "# 참고) 정답을 분류 -> 원핫인코딩 FM : 너무 귀찮음!\n",
    "# loss 함수를 지정하는 과정에서 앞에 sparse_ ~~\n",
    "# 굳이 정답을 원핫 인코딩을 안 하고, 라벨 인코딩으로 넣어도 됨!\n",
    "\n",
    "# 참고) 여기서는 정답지(라벨인코딩된 거 그대로 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AzIOf_ldxtA",
    "outputId": "a2832290-18ae-4cd0-dc6e-bd7361b1e8de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwCLCJDHzaoa"
   },
   "source": [
    "#### 모델 학습 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XH4hXTGydy7P"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # 이런 loss는 정답을 무조건 one_hot 인코딩\n",
    "    # loss = \"categorical_crossentropy\" 에서\n",
    "    # sparse 를 붙이면 라벨 인코딩 가능\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukEyc3vRzc6C"
   },
   "source": [
    "#### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0Misk2-eOwH",
    "outputId": "5c2a8c81-5f1c-4824-f7cd-240226e97308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "352/352 [==============================] - 10s 12ms/step - loss: 0.5007 - accuracy: 0.8232 - val_loss: 0.3829 - val_accuracy: 0.8598\n",
      "Epoch 2/20\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.3423 - accuracy: 0.8755 - val_loss: 0.3678 - val_accuracy: 0.8657\n",
      "Epoch 3/20\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 0.2839 - accuracy: 0.8960 - val_loss: 0.3616 - val_accuracy: 0.8737\n",
      "Epoch 4/20\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 0.2400 - accuracy: 0.9120 - val_loss: 0.3787 - val_accuracy: 0.8675\n",
      "Epoch 5/20\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.2047 - accuracy: 0.9243 - val_loss: 0.3860 - val_accuracy: 0.8758\n",
      "Epoch 6/20\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 0.1721 - accuracy: 0.9377 - val_loss: 0.4351 - val_accuracy: 0.8725\n",
      "Epoch 7/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 0.1500 - accuracy: 0.9458 - val_loss: 0.4824 - val_accuracy: 0.8695\n",
      "Epoch 8/20\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.1361 - accuracy: 0.9505 - val_loss: 0.5095 - val_accuracy: 0.8619\n",
      "Epoch 9/20\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 0.1239 - accuracy: 0.9535 - val_loss: 0.5468 - val_accuracy: 0.8689\n",
      "Epoch 10/20\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.1081 - accuracy: 0.9598 - val_loss: 0.6106 - val_accuracy: 0.8671\n",
      "Epoch 11/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 0.0955 - accuracy: 0.9649 - val_loss: 0.6439 - val_accuracy: 0.8672\n",
      "Epoch 12/20\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.0859 - accuracy: 0.9679 - val_loss: 0.7203 - val_accuracy: 0.8661\n",
      "Epoch 13/20\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 0.0844 - accuracy: 0.9696 - val_loss: 0.7266 - val_accuracy: 0.8661\n",
      "Epoch 14/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 0.0765 - accuracy: 0.9725 - val_loss: 0.7834 - val_accuracy: 0.8684\n",
      "Epoch 15/20\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 0.0616 - accuracy: 0.9781 - val_loss: 0.8428 - val_accuracy: 0.8646\n",
      "Epoch 16/20\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.0707 - accuracy: 0.9753 - val_loss: 0.8636 - val_accuracy: 0.8689\n",
      "Epoch 17/20\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.0563 - accuracy: 0.9799 - val_loss: 0.9035 - val_accuracy: 0.8671\n",
      "Epoch 18/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 0.0654 - accuracy: 0.9770 - val_loss: 0.9986 - val_accuracy: 0.8668\n",
      "Epoch 19/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 0.0496 - accuracy: 0.9822 - val_loss: 1.0550 - val_accuracy: 0.8639\n",
      "Epoch 20/20\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 0.0451 - accuracy: 0.9833 - val_loss: 1.0693 - val_accuracy: 0.8673\n"
     ]
    }
   ],
   "source": [
    "# 실제 학습을 진행\n",
    "history = model.fit(\n",
    "    train_X, train_y,\n",
    "    epochs = 20,\n",
    "    validation_split = 0.25,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9AWGZ1CMekOT"
   },
   "outputs": [],
   "source": [
    "# conv : stride : 샘플링에 대한 빈도\n",
    "# pooling : 대표화 (Feature Map 에 대한 대표화)\n",
    "# + 분류에서 DNN dropout 활용해서 연결을 끊어내기\n",
    "# -> overfit 줄이고자 함\n",
    "\n",
    "# 초기 CNN : conv + pool + conv + pool\n",
    "# VGG 논문 이후 : conv + conv + conv + pool etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63xCN3ZQgDYB",
    "outputId": "a8cefbf9-893e-4def-db0e-ffda8c06a056"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x79ed5c0e6980>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시도1) 초기 버전으로 시도...\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D( input_shape=(28,28,1),kernel_size=(3,3),filters = 16),\n",
    "    tf.keras.layers.MaxPooling2D( pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=32),\n",
    "    tf.keras.layers.MaxPooling2D( pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout( rate= 0.3),\n",
    "    tf.keras.layers.Dense( units = 128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout( rate= 0.3),\n",
    "\n",
    "    tf.keras.layers.Dense( units = 10, activation=\"softmax\")\n",
    "])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7lS3b3lhIzV",
    "outputId": "a342f736-3d96-4cb0-f744-94085a64c42c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 64)          18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               73856     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98442 (384.54 KB)\n",
      "Trainable params: 98442 (384.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ip4luWzYhTPz"
   },
   "outputs": [],
   "source": [
    "# 동일한 구조인대 대표화 & 중간에 짜르기\n",
    "# 400만개 파라미터  -> 10만개 정도로 줄이는 것\n",
    "# 내가 어떻게 설계하는지에 따라서 엄청나게 다양성이 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB38sHKx01-W"
   },
   "source": [
    "#### 모델 셋팅 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kd6OMF3ijH3X"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQW7V0g7jJEn",
    "outputId": "fc953e62-f717-4543-e6d5-06d664bbc220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "352/352 [==============================] - 5s 6ms/step - loss: 0.6993 - accuracy: 0.7425 - val_loss: 0.4782 - val_accuracy: 0.8186\n",
      "Epoch 2/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.4629 - accuracy: 0.8330 - val_loss: 0.3810 - val_accuracy: 0.8600\n",
      "Epoch 3/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.3995 - accuracy: 0.8532 - val_loss: 0.3596 - val_accuracy: 0.8695\n",
      "Epoch 4/20\n",
      "352/352 [==============================] - 2s 7ms/step - loss: 0.3664 - accuracy: 0.8693 - val_loss: 0.3454 - val_accuracy: 0.8735\n",
      "Epoch 5/20\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.3457 - accuracy: 0.8748 - val_loss: 0.3131 - val_accuracy: 0.8858\n",
      "Epoch 6/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.3302 - accuracy: 0.8807 - val_loss: 0.3071 - val_accuracy: 0.8867\n",
      "Epoch 7/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.3170 - accuracy: 0.8837 - val_loss: 0.3032 - val_accuracy: 0.8883\n",
      "Epoch 8/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.3089 - accuracy: 0.8855 - val_loss: 0.2955 - val_accuracy: 0.8909\n",
      "Epoch 9/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2990 - accuracy: 0.8894 - val_loss: 0.2985 - val_accuracy: 0.8937\n",
      "Epoch 10/20\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2899 - accuracy: 0.8922 - val_loss: 0.2984 - val_accuracy: 0.8907\n",
      "Epoch 11/20\n",
      "352/352 [==============================] - 2s 7ms/step - loss: 0.2849 - accuracy: 0.8963 - val_loss: 0.2901 - val_accuracy: 0.8943\n",
      "Epoch 12/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2753 - accuracy: 0.8999 - val_loss: 0.2802 - val_accuracy: 0.8961\n",
      "Epoch 13/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2675 - accuracy: 0.9018 - val_loss: 0.2824 - val_accuracy: 0.8965\n",
      "Epoch 14/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2588 - accuracy: 0.9055 - val_loss: 0.2906 - val_accuracy: 0.8967\n",
      "Epoch 15/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2568 - accuracy: 0.9052 - val_loss: 0.2744 - val_accuracy: 0.9012\n",
      "Epoch 16/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2500 - accuracy: 0.9081 - val_loss: 0.2725 - val_accuracy: 0.9020\n",
      "Epoch 17/20\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2439 - accuracy: 0.9091 - val_loss: 0.2891 - val_accuracy: 0.8971\n",
      "Epoch 18/20\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.2376 - accuracy: 0.9117 - val_loss: 0.2865 - val_accuracy: 0.8989\n",
      "Epoch 19/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2363 - accuracy: 0.9122 - val_loss: 0.2753 - val_accuracy: 0.9018\n",
      "Epoch 20/20\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2318 - accuracy: 0.9154 - val_loss: 0.2805 - val_accuracy: 0.8992\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_X, train_y,\n",
    "    epochs = 20,\n",
    "    validation_split =0.25,\n",
    "    batch_size= 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ScnqJohVjJs8"
   },
   "outputs": [],
   "source": [
    "#### 모델링에서 중요한 기본적인 부분은 Bias-Variance\n",
    "#     ==> UnderFit ~~~ 적당한fit ~~~~ overFit\n",
    "# 기존의 ML ) HPT을 중심으로 해당하는 모델의 학습을\n",
    "#            max_depth etc\n",
    "# Deep Learning ) 모델의 구조를 통해서 조절\n",
    "#             : 연결성을 중심으로 처리를 함\n",
    "\n",
    "\n",
    "# ---> 모델을 경량화를 했더니 학습이 더 잘된다!!!\n",
    "# 더 학습을 해도 될 것 같다\n",
    "# 지금까지는 OverFit은 아닌거 같으니, 더 해보고 싶다\n",
    "# callback 을 사용해서 모니터링을 해야함\n",
    "# + 중간에 때려칠지 & + 중간에 모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paRkJxGt1IdD"
   },
   "source": [
    "#### 모델 저장\n",
    "    * ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "g56SxqTyjMXY"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmTTw7NljN9Q",
    "outputId": "bf3ca853-3e54-4a02-83d9-660e5d7cae6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "345/352 [============================>.] - ETA: 0s - loss: 0.2208 - accuracy: 0.9175\n",
      "Epoch 1: saving model to training/cp-0001.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2204 - accuracy: 0.9176 - val_loss: 0.2727 - val_accuracy: 0.9032\n",
      "Epoch 2/20\n",
      "346/352 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9199\n",
      "Epoch 2: saving model to training/cp-0002.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2165 - accuracy: 0.9199 - val_loss: 0.2834 - val_accuracy: 0.8955\n",
      "Epoch 3/20\n",
      "350/352 [============================>.] - ETA: 0s - loss: 0.2125 - accuracy: 0.9201\n",
      "Epoch 3: saving model to training/cp-0003.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2126 - accuracy: 0.9201 - val_loss: 0.2769 - val_accuracy: 0.9027\n",
      "Epoch 4/20\n",
      "343/352 [============================>.] - ETA: 0s - loss: 0.2119 - accuracy: 0.9194\n",
      "Epoch 4: saving model to training/cp-0004.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2118 - accuracy: 0.9198 - val_loss: 0.2765 - val_accuracy: 0.9052\n",
      "Epoch 5/20\n",
      "348/352 [============================>.] - ETA: 0s - loss: 0.2099 - accuracy: 0.9228\n",
      "Epoch 5: saving model to training/cp-0005.ckpt\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 0.2100 - accuracy: 0.9226 - val_loss: 0.2783 - val_accuracy: 0.9053\n",
      "Epoch 6/20\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2066 - accuracy: 0.9219\n",
      "Epoch 6: saving model to training/cp-0006.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2065 - accuracy: 0.9219 - val_loss: 0.2743 - val_accuracy: 0.9029\n",
      "Epoch 7/20\n",
      "342/352 [============================>.] - ETA: 0s - loss: 0.2047 - accuracy: 0.9242\n",
      "Epoch 7: saving model to training/cp-0007.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.2050 - accuracy: 0.9241 - val_loss: 0.2724 - val_accuracy: 0.9044\n",
      "Epoch 8/20\n",
      "347/352 [============================>.] - ETA: 0s - loss: 0.1979 - accuracy: 0.9259\n",
      "Epoch 8: saving model to training/cp-0008.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1979 - accuracy: 0.9259 - val_loss: 0.2711 - val_accuracy: 0.9073\n",
      "Epoch 9/20\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1981 - accuracy: 0.9252\n",
      "Epoch 9: saving model to training/cp-0009.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1979 - accuracy: 0.9253 - val_loss: 0.2711 - val_accuracy: 0.9052\n",
      "Epoch 10/20\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1965 - accuracy: 0.9260\n",
      "Epoch 10: saving model to training/cp-0010.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1964 - accuracy: 0.9260 - val_loss: 0.2732 - val_accuracy: 0.9058\n",
      "Epoch 11/20\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1938 - accuracy: 0.9280\n",
      "Epoch 11: saving model to training/cp-0011.ckpt\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1939 - accuracy: 0.9280 - val_loss: 0.2778 - val_accuracy: 0.9039\n",
      "Epoch 12/20\n",
      "349/352 [============================>.] - ETA: 0s - loss: 0.1900 - accuracy: 0.9282\n",
      "Epoch 12: saving model to training/cp-0012.ckpt\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 0.1898 - accuracy: 0.9283 - val_loss: 0.2955 - val_accuracy: 0.9035\n",
      "Epoch 13/20\n",
      "348/352 [============================>.] - ETA: 0s - loss: 0.1880 - accuracy: 0.9297\n",
      "Epoch 13: saving model to training/cp-0013.ckpt\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1883 - accuracy: 0.9295 - val_loss: 0.2798 - val_accuracy: 0.9056\n",
      "Epoch 14/20\n",
      "349/352 [============================>.] - ETA: 0s - loss: 0.1872 - accuracy: 0.9297\n",
      "Epoch 14: saving model to training/cp-0014.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1871 - accuracy: 0.9297 - val_loss: 0.2806 - val_accuracy: 0.9042\n",
      "Epoch 15/20\n",
      "343/352 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9303\n",
      "Epoch 15: saving model to training/cp-0015.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1831 - accuracy: 0.9306 - val_loss: 0.2852 - val_accuracy: 0.9038\n",
      "Epoch 16/20\n",
      "340/352 [===========================>..] - ETA: 0s - loss: 0.1800 - accuracy: 0.9306\n",
      "Epoch 16: saving model to training/cp-0016.ckpt\n",
      "352/352 [==============================] - 2s 5ms/step - loss: 0.1802 - accuracy: 0.9305 - val_loss: 0.2902 - val_accuracy: 0.9033\n",
      "Epoch 17/20\n",
      "349/352 [============================>.] - ETA: 0s - loss: 0.1795 - accuracy: 0.9325\n",
      "Epoch 17: saving model to training/cp-0017.ckpt\n",
      "352/352 [==============================] - 2s 6ms/step - loss: 0.1793 - accuracy: 0.9325 - val_loss: 0.2907 - val_accuracy: 0.9054\n",
      "Epoch 18/20\n",
      "348/352 [============================>.] - ETA: 0s - loss: 0.1771 - accuracy: 0.9323\n",
      "Epoch 18: saving model to training/cp-0018.ckpt\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 0.1773 - accuracy: 0.9322 - val_loss: 0.2975 - val_accuracy: 0.9036\n"
     ]
    }
   ],
   "source": [
    "# --> epochs를 일단 크게 세팅을 하고,,,\n",
    "#     early stop을 통해서 더이상 성능 향상이 없으면 stop\n",
    "# --> 중간 중간 모델의 weights를 저장(모델 저장)\n",
    "cp_path = \"training/cp-{epoch:04d}.ckpt\"\n",
    "cp_dir = os.path.dirname(cp_path) # training\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    cp_path,\n",
    "    verbose = 1,\n",
    "    save_weights_only = True\n",
    ")\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience = 10 # 참을 횟수...갱신이 안 되는 횟수..\n",
    ")\n",
    "\n",
    "history = model.fit( train_X, train_y,\n",
    "                    epochs = 20, #아까 20번 돌아서 마지막 부분에서부터 이어서 시작함.엄밀히 말하면 220번째임\n",
    "                     validation_split = 0.25,\n",
    "                     batch_size = 128,\n",
    "                     callbacks = [cp_callback, es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeaYLb11kQ0X"
   },
   "outputs": [],
   "source": [
    "# 참고) 위에서는 처음 20에포크 돌린 이후에 epoch세팅만큼 돌 거라\n",
    "#       시작점이 높이 시작을 함!!!! 0.9X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtwaFEki1Z4v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6K6g2rklj70",
    "outputId": "ea0dcb64-abf4-44e1-9910-30452c77e857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2921 - accuracy: 0.8959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29213982820510864, 0.8959000110626221]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 앞에서 학습한 결과들을 바탕으로 제일 좋을 것 같은.\n",
    "# 모델의 weights를 가지고 오겠습니다!!!\n",
    "# ==> 상황마다 다르기에,,,스스로 결정하셔야 함!!!!\n",
    "# 주의사항) 폴더에 보이는 파일명이 아니라 내가 저장한 양식대로\n",
    "load_cp_weights = \"training/cp-0011.ckpt\"\n",
    "\n",
    "# 모델의 골조 : model 변수.....weights 담겨는 있음..\n",
    "# --> 구조는 동일하니, 안에 인테리어만 싹 가는것!!!!\n",
    "# 참고) 다른 사람이 사용할 때에는 모델 구조도 전달을\n",
    "model.load_weights(load_cp_weights )\n",
    "\n",
    "# 실제 평가!!!!!!!!!\n",
    "model.evaluate( test_X, test_y)\n",
    "# --> 정답지를 그냥 활용할 수 있는 이유는\n",
    "#     compile에서 loss에  sparse로 설정을 해서임!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HFG3dYOls_b"
   },
   "outputs": [],
   "source": [
    "# 대략 구조는 파악을 하고,,,\n",
    "# 완전히 최적을 해야한다면, HPT을 한다면,\n",
    "\n",
    "# 구조적인 부분에 대한 여러 실험들을 해야함\n",
    "# + 필터의 수, 필터의 사이즈, 레이어의 수 etc\n",
    "\n",
    "# ===> optuna로 실험을 할 수 있음!!!!!!!!!!!!!\n",
    "# 단, 시간이 엄청 걸리는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YefYx3ZbmbHp"
   },
   "outputs": [],
   "source": [
    "# 개선방향 (논문, 리포트 분석 : 논문대략적이 것들을 파악)\n",
    "    # -> 잘 되는 모델들을 조사해서 가져다가 사용하자\n",
    "# 데이터를 보강하자\n",
    "    # -> 잘 되는 모델을 가져다가 사용하자( 조금 튜닝 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLGLyuNsh3Cn"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
