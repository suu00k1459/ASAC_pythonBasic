{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlau-Xdhv1Lz",
        "outputId": "c54d0edd-10a4-4efb-81c2-b194d7f6ae08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import time"
      ],
      "metadata": {
        "id": "WBVc8-F0v4s_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten , Dropout\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "zSYxgWUov6m0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 불러오기"
      ],
      "metadata": {
        "id": "QVlZBE8n2yXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_X, train_y),(test_X, test_y) = fashion_mnist.load_data()\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(test_X.shape)\n",
        "print(test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u8ZSgS0v9S-",
        "outputId": "3543804b-e7f6-4140-ef44-7f5539daced4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리\n",
        "\n",
        "train_X = train_X/255.0\n",
        "test_X = test_X /255.0\n",
        "\n",
        "train_X = train_X.reshape(-1 ,28,28,1)  # 3d ---> 4d\n",
        "test_X  = test_X.reshape(-1, 28,28,1)\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_X[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOFoZk5q25JK",
        "outputId": "11855273-1f24-4648-8947-d27f62b04a5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 구조 설계"
      ],
      "metadata": {
        "id": "nWr2KpFp3LXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_vgg_fashion = tf.keras.Sequential(\n",
        "    [\n",
        "        # 원본 입력을 기준으로 설계.... : 224 224 RGB\n",
        "        # --> 28 28 1\n",
        "        Conv2D( input_shape=(28,28,1), kernel_size=(3,3),\n",
        "               filters=64, padding =\"same\", activation=\"relu\"),\n",
        "\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters=64, padding =\"same\", activation=\"relu\"),\n",
        "        MaxPool2D( pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "\n",
        "\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters=128, padding =\"same\", activation=\"relu\"),\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters=128, padding =\"same\", activation=\"relu\"),\n",
        "        MaxPool2D( pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "\n",
        "\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters=256, padding =\"same\", activation=\"relu\"),\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters=256, padding =\"same\", activation=\"relu\"),\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters=256, padding =\"same\", activation=\"relu\"),\n",
        "        MaxPool2D( pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "\n",
        "\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters=512, padding =\"same\", activation=\"relu\"),\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters=512, padding =\"same\", activation=\"relu\"),\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters=512, padding =\"same\", activation=\"relu\"),\n",
        "        # MaxPool2D( pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters=512, padding =\"same\", activation=\"relu\"),\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters=512, padding =\"same\", activation=\"relu\"),\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters=512, padding =\"same\", activation=\"relu\"),\n",
        "        # MaxPool2D( pool_size=(2,2), strides=(2,2)),\n",
        "        # ===> 기본적인 이미지가 가지고 있는 특징 추출!!!!!\n",
        "\n",
        "        # 분류를 위한 NN\n",
        "        # 1) 특징을 분류 Faltten\n",
        "        Flatten(),\n",
        "\n",
        "\n",
        "        # 2) 분류용 HL 적층!!!!\n",
        "        Dense( units=4096, activation=\"relu\"),\n",
        "        Dense( units=4096, activation=\"relu\"),\n",
        "\n",
        "\n",
        "        # 3) 출력용 --> 내 모델의 목적에 맞춰야함!!\n",
        "        #    나는 10개만 하면 됨...수정..\n",
        "        Dense( units=10, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "model_vgg_fashion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDKp1AMzv-Ev",
        "outputId": "a824b573-54d5-48a2-f81b-0a83ed76ffa5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.engine.sequential.Sequential at 0x7b3445288f10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 위의 간단한 구조들을 바탕으로 좀 더 디테일한 구조들에 대해서 실험\n",
        "# 1. 내가 무엇을 보고 최적화를 할지 함수로 설정\n",
        "# ===> 전에 ML을 할 때는 단순 파라미터들의 조합\n",
        "# ===> DL : 모델의 구조들이 기본적인 파라미터\n",
        "#      모델의 구조들에 대한 실험을 함수로 구현을 해야함!!!!\n",
        "#      ++ 노드의 수 ++ lr ++ AF etc\n",
        "# :: 내가 하려고 하는 목적에 맞는 함수를 직접 만드셔야 함!!!"
      ],
      "metadata": {
        "id": "4y6dkkjcwBD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step1) optuna에서 주어진 파라미터에 맞는 모델 구조!!!! 함수\n",
        "#  ---> 입력\n",
        "#       1) 1번 conv layer에서 몇 개의 Conv을 진행할지..(2,3)\n",
        "#       2) 2번 conv layer에서 몇 개의 conv를 진행할지\n",
        "#       3) dropout 같은 구조도 하고 싶으면 rate테스트\n",
        "#       4) 분류하는 곳에서 dense의 node 수를 조절하고\n",
        "\n",
        "# 내가 하고자 하는 구조에 대한 생성함수\n",
        "# (optuna가 찾는 목적함수와 다른 함수)\n",
        "\n",
        "# optuna의 objectitve Function이 제시하는 값에 따른 구조를 생성하는 함수"
      ],
      "metadata": {
        "id": "TDB5S3ZnwCd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3jHM7TlP4RGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model( num_layers_conv1, num_filters_conv1,\n",
        "                  num_layers_conv2, num_filters_conv2,\n",
        "                  dnn_dropout_rate, dnn_num_node) :\n",
        "# 여기에서는 모델을 설계하는 방식 중\n",
        "# 기존의 리스트에 레이어를 적층하는 구조 방식이라\n",
        "# 리스트의 append를 이용해서 직접 추가하도록 하겠음\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  # 1번 conv\n",
        "  model.add( Conv2D (input_shape = (28,28,1),\n",
        "                     kernel_size = (2,2), filters = 32, padding = \"same\", activation =\"relu\")\n",
        "\n",
        "  )\n",
        "\n",
        "  for i in range(num_layers_conv1):\n",
        "    model.add(Conv2D(input_shape = (28,28,1),\n",
        "                       kernel_size = (2,2), filters = num_filters_conv1, padding = \"same\", activation =\"relu\"))\n",
        "\n",
        "  model.add( MaxPool2D( pool_size=(2,2), strides=(2,2)) )\n",
        "\n",
        "\n",
        "  # 2번 conv\n",
        "  model.add( Conv2D (kernel_size = (2,2), filters = 32, padding = \"same\", activation =\"relu\"))\n",
        "\n",
        "  for i in range(num_layers_conv2) :\n",
        "    model.add( Conv2D (input_shape = (28,28,1),\n",
        "                     kernel_size = (2,2), filters = num_filters_conv2, padding = \"same\", activation =\"relu\"))\n",
        "\n",
        "  model.add( MaxPool2D( pool_size=(2,2), strides=(2,2)) )\n",
        "\n",
        "\n",
        "# 분류를 위한 모델 셜계\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units = dnn_num_node, activation =\"relu\"))\n",
        "  model.add(Dropout(rate = dnn_dropout_rate))\n",
        "  model.add(Dense(units = dnn_num_node, activation =\"relu\"))\n",
        "  model.add(Dropout(rate = dnn_dropout_rate))\n",
        "\n",
        "# 출력층을 설계\n",
        "  model.add(Dense( units=10, activation=\"softmax\"))\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "dm2sbEKewsMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step2) 최적의 값을 찾는 objective function 설계!!!!\n",
        "# ===> 앞에서 ML했던 방식 그대로...\n",
        "def object_vgg(trail):\n",
        "    # 혹시 뒤에서 keras 백단에서 살아있을 때...\n",
        "    # ===> 클리어해서 정리하고 시작하자!!!!\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  # 내가 테스트할 파라미터들을 제안 받는 것들 세팅!!!!!!!!\n",
        "  num_layers_conv1 = trail.suggest_int(\"num_layers_conv1\",1,4)\n",
        "  num_filters_conv1 =trail.suggest_int(\"num_filters_conv1\",32,128)\n",
        "  num_layers_conv2 = trail.suggest_int(\"num_layers_conv2\",1,4)\n",
        "  num_filters_conv2 = trail.suggest_int(\"num_filters_conv2\",182,256)\n",
        "  dnn_dropout_rate = trail.suggest_float(\"dnn_dropout_rate\", 0.1, 0.4)\n",
        "  dnn_num_node =  trail.suggest_int(\"dnn_num_node\", 128, 2048)\n",
        "# -> 여기까지 모델 설계도에 관련된 파라미터\n",
        "\n",
        "# + 모델의 학습하는 영향을 미치는 파라미터도 중요\n",
        "# -> 여기서는 간단하게 최적화 방법만 선택\n",
        "\n",
        "# learning 과 관련된 HPT\n",
        "# + lr 학습에서 테스트도 하는 것도 중요함\n",
        "# + batch_size etc 테스트의 영역\n",
        "\n",
        "  optimizer = trail.suggest_categorical(\"optimizer\",[\"adam\", \"sgd\"])\n",
        "\n",
        "  model  = create_model( num_layers_conv1, num_filters_conv1,\n",
        "                        num_layers_conv2, num_filters_conv2,\n",
        "                        dnn_dropout_rate, dnn_num_node)\n",
        "\n",
        "\n",
        "\n",
        "  model.compile(\n",
        "      optimizer = optimizer,\n",
        "      loss = \"sparse_categorical_crossentropy\",\n",
        "      metrics = [\"accuracy\"]\n",
        "  )\n",
        "  # 제안 받은 모델 구조도 + 학습 방식에 것을 적용!\n",
        "  # + 시간 관계상 확 줄여서 진행하겠음.\n",
        "  # callback( early stopping을 주로 같이 )\n",
        "\n",
        "\n",
        "  history = model.fit( train_X , train_y,\n",
        "                      epochs = 2, batch_size = 1024,\n",
        "                       validation_split = 0.25)\n",
        "   # objective function의 타겟\n",
        "   # -> 주관적으로 val_accuracy를 타겟으로 하겠음\n",
        "\n",
        "\n",
        "\n",
        "  score = history.history[\"val_accuracy\"][-1]\n",
        "\n",
        "\n",
        "  return score\n"
      ],
      "metadata": {
        "id": "8BcDQtdM01k7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 실제 test\n",
        "study_my_vgg = optuna.create_study(direction = \"maximize\")\n",
        "\n",
        "# 원래는 엄청 시도해야하는데 시도 횟수도 줄여서\n",
        "study_my_vgg.optimize(object_vgg, n_trials = 2, n_jobs= -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjPzqF6c5-x5",
        "outputId": "7f728dfb-3575-4f06-f23c-661abe9277aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-06 14:26:00,401] A new study created in memory with name: no-name-433c59f4-bdc6-4249-b6c4-9da5f92c72d3\n",
            "[W 2024-06-06 14:26:00,412] Trial 0 failed with parameters: {'num_layers_conv1': 4, 'num_filters_conv1': 126, 'num_layers_conv2': 3, 'num_filters_conv2': 198, 'dnn_dropout_rate': 0.2576763241781195, 'dnn_num_node': 331, 'optimizer': 'adam'} because of the following error: NameError(\"name 'create_model' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-7-1a299d5f4c34>\", line 26, in object_vgg\n",
            "    model  = create_model( num_layers_conv1, num_filters_conv1,\n",
            "NameError: name 'create_model' is not defined\n",
            "[W 2024-06-06 14:26:00,417] Trial 0 failed with value None.\n",
            "[W 2024-06-06 14:26:00,416] Trial 1 failed with parameters: {'num_layers_conv1': 4, 'num_filters_conv1': 128, 'num_layers_conv2': 1, 'num_filters_conv2': 248, 'dnn_dropout_rate': 0.31653556096747804, 'dnn_num_node': 289, 'optimizer': 'sgd'} because of the following error: NameError(\"name 'create_model' is not defined\").\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-7-1a299d5f4c34>\", line 26, in object_vgg\n",
            "    model  = create_model( num_layers_conv1, num_filters_conv1,\n",
            "NameError: name 'create_model' is not defined\n",
            "[W 2024-06-06 14:26:00,422] Trial 1 failed with value None.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YtLeW3Hv7T3J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}